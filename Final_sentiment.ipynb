{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca41a711-05e0-4a17-a9ff-ac8afcdc91fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "redmine_url = \"https://new-redmine5.senseitech.com\"\n",
    "api_key = \"9dc4f57007d2f560ae091dfd861ad711070dbb25\"\n",
    "\n",
    "# Headers for authentication\n",
    "headers = {\n",
    "    'X-Redmine-API-Key': api_key,\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "# Function to fetch all issues with pagination\n",
    "def get_all_issues():\n",
    "    issues = []\n",
    "    limit = 100  # Number of issues per page (max: 100)\n",
    "    offset = 0   # Start from the first issue\n",
    "\n",
    "    while True:\n",
    "        issues_url = f\"{redmine_url}/issues.json?limit={limit}&offset={offset}\"\n",
    "        response = requests.get(issues_url, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            current_issues = data.get('issues', [])\n",
    "            \n",
    "            # If there are no more issues, break the loop\n",
    "            if not current_issues:\n",
    "                break\n",
    "            \n",
    "            # Add fetched issues to the list\n",
    "            issues.extend(current_issues)\n",
    "            offset += limit\n",
    "        else:\n",
    "            print(f\"Failed to fetch issues. Status Code: {response.status_code}\")\n",
    "            break\n",
    "\n",
    "    return issues\n",
    "\n",
    "# Function to fetch a specific issue by issue_id\n",
    "def get_issue(issue_id):\n",
    "    issue_url = f\"{redmine_url}/issues/{issue_id}.json\"\n",
    "    response = requests.get(issue_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        issue_details = response.json().get('issue', {})\n",
    "        return issue_details\n",
    "    else:\n",
    "        print(f\"Failed to fetch issue details for ID {issue_id}. Status Code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Fetch all issues\n",
    "all_issues = get_all_issues()\n",
    "\n",
    "if all_issues:\n",
    "    for issue in all_issues:\n",
    "        issue_id = issue['id']  # Dynamically set the issue_id\n",
    "        issue_details = get_issue(issue_id)\n",
    "        \n",
    "        if issue_details:\n",
    "            print(f\"Issue ID: {issue_details['id']}\")\n",
    "            print(f\"Subject: {issue_details['subject']}\")\n",
    "            print(f\"Description: {issue_details['description']}\")\n",
    "            print(f\"Status: {issue_details['status']['name']}\")\n",
    "            print(f\"Priority: {issue_details['priority']['name']}\")\n",
    "            print(f\"Assigned to: {issue_details.get('assigned_to', {}).get('name', 'Not assigned')}\")\n",
    "        print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7adeebe9-48ec-4ae3-a602-6911e9f170df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ssure\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\ssure\\Desktop\\Ticket_management\\env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssure\\Desktop\\Ticket_management\\env\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion detection completed and saved to issue_emotions_detected.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import pipeline\n",
    "\n",
    "# Download stopwords from NLTK (if not already done)\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Load the CSV file with ticket descriptions\n",
    "df = pd.read_csv('redmine_issues.csv')\n",
    "\n",
    "# Initialize the emotion analysis pipeline using a pre-trained model for emotion classification\n",
    "emotion_classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)\n",
    "\n",
    "# Define a mapping to align model output with your target emotions\n",
    "emotion_mapping = {\n",
    "    'anger': 'Anger',\n",
    "    'sadness': 'Disappointment',\n",
    "    'fear': 'Confusion',\n",
    "    'joy': 'Satisfaction',\n",
    "    'neutral': 'Neutral',\n",
    "    'disgust': 'Frustration'\n",
    "}\n",
    "\n",
    "# Function to preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters, numbers, and punctuation\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Function to detect emotion in a description\n",
    "def detect_emotion(text):\n",
    "    # Preprocess the text\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "    \n",
    "    # Truncate text if it's too long for the model (max 512 tokens)\n",
    "    truncated_text = preprocessed_text[:512]\n",
    "    \n",
    "    # Get emotion predictions\n",
    "    predictions = emotion_classifier(truncated_text)\n",
    "    \n",
    "    # Extract the top emotion with the highest score\n",
    "    top_emotion = max(predictions[0], key=lambda x: x['score'])['label']\n",
    "    \n",
    "    # Map the detected emotion to the specified categories\n",
    "    return emotion_mapping.get(top_emotion, 'Neutral')\n",
    "\n",
    "# Apply emotion detection to each ticket description\n",
    "df['Detected Emotion'] = df['Description'].apply(lambda text: detect_emotion(str(text)))\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "df[['Description', 'Detected Emotion']].to_csv('issue_emotions_detected.csv', index=False)\n",
    "\n",
    "print(\"Emotion detection completed and saved to issue_emotions_detected.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e31304c-d3c0-4ef7-a707-ed7face6bf74",
   "metadata": {},
   "source": [
    "AFTER PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db787315-c685-49d2-bd91-38491c1b517e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issues have been successfully saved to redmine_issues.csv.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "redmine_url = \"https://new-redmine5.senseitech.com\"\n",
    "api_key = \"9dc4f57007d2f560ae091dfd861ad711070dbb25\"\n",
    "\n",
    "# Headers for authentication\n",
    "headers = {\n",
    "    'X-Redmine-API-Key': api_key,\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "# Function to fetch all issues with pagination\n",
    "def get_all_issues():\n",
    "    issues = []\n",
    "    limit = 100  # Number of issues per page (max: 100)\n",
    "    offset = 0   # Start from the first issue\n",
    "\n",
    "    while True:\n",
    "        issues_url = f\"{redmine_url}/issues.json?limit={limit}&offset={offset}\"\n",
    "        response = requests.get(issues_url, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            current_issues = data.get('issues', [])\n",
    "            \n",
    "            # If there are no more issues, break the loop\n",
    "            if not current_issues:\n",
    "                break\n",
    "            \n",
    "            # Add fetched issues to the list\n",
    "            issues.extend(current_issues)\n",
    "            offset += limit\n",
    "        else:\n",
    "            print(f\"Failed to fetch issues. Status Code: {response.status_code}\")\n",
    "            break\n",
    "\n",
    "    return issues\n",
    "\n",
    "# Function to fetch a specific issue by issue_id\n",
    "def get_issue(issue_id):\n",
    "    issue_url = f\"{redmine_url}/issues/{issue_id}.json\"\n",
    "    response = requests.get(issue_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        issue_details = response.json().get('issue', {})\n",
    "        return issue_details\n",
    "    else:\n",
    "        print(f\"Failed to fetch issue details for ID {issue_id}. Status Code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Fetch all issues\n",
    "all_issues = get_all_issues()\n",
    "\n",
    "# Prepare data for DataFrame\n",
    "issue_data = []\n",
    "if all_issues:\n",
    "    for issue in all_issues:\n",
    "        issue_id = issue['id']  # Dynamically set the issue_id\n",
    "        issue_details = get_issue(issue_id)\n",
    "        \n",
    "        if issue_details:\n",
    "            issue_info = {\n",
    "                \"Issue ID\": issue_details['id'],\n",
    "                \"Subject\": issue_details['subject'],\n",
    "                \"Description\": issue_details.get('description', '').replace('\\n', ' '),  # Replace newlines with spaces\n",
    "                \"Status\": issue_details['status']['name'],\n",
    "                \"Priority\": issue_details['priority']['name'] if 'priority' in issue_details else 'Not specified',\n",
    "                \"Assigned To\": issue_details.get('assigned_to', {}).get('name', 'Not assigned')\n",
    "            }\n",
    "            issue_data.append(issue_info)\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df_issues = pd.DataFrame(issue_data)\n",
    "\n",
    "# Save DataFrame to a CSV file\n",
    "df_issues.to_csv('redmine_issues.csv', index=False)\n",
    "\n",
    "print(\"Issues have been successfully saved to redmine_issues.csv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3ce84c-06ff-45a1-a421-9658ede61656",
   "metadata": {},
   "source": [
    "WITHOUT PREPROCESSING\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00f8e3b3-2a6f-4fb4-b1aa-960c80773122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssure\\Desktop\\Ticket_management\\env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssure\\Desktop\\Ticket_management\\env\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion detection completed and saved to issue_emotions_detected.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the CSV file with ticket descriptions\n",
    "df = pd.read_csv('redmine_issues.csv')\n",
    "\n",
    "# Initialize the emotion analysis pipeline using a pre-trained model for emotion classification\n",
    "emotion_classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)\n",
    "\n",
    "# Define a mapping to align model output with your target emotions\n",
    "emotion_mapping = {\n",
    "    'anger': 'Anger',\n",
    "    'sadness': 'Disappointment',\n",
    "    'fear': 'Confusion',\n",
    "    'joy': 'Satisfaction',\n",
    "    'neutral': 'Neutral',\n",
    "    'disgust': 'Frustration'\n",
    "}\n",
    "\n",
    "# Function to detect emotion in a description\n",
    "def detect_emotion(text):\n",
    "    # Truncate text if it's too long for the model (max 512 tokens)\n",
    "    truncated_text = text[:512]\n",
    "    \n",
    "    # Get emotion predictions\n",
    "    predictions = emotion_classifier(truncated_text)\n",
    "    \n",
    "    # Extract the top emotion with the highest score\n",
    "    top_emotion = max(predictions[0], key=lambda x: x['score'])['label']\n",
    "    \n",
    "    # Map the detected emotion to the specified categories\n",
    "    return emotion_mapping.get(top_emotion, 'Neutral')\n",
    "\n",
    "# Apply emotion detection to each ticket description\n",
    "df['Detected Emotion'] = df['Description'].apply(lambda text: detect_emotion(str(text)))\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "df[['Description', 'Detected Emotion']].to_csv('issue_emotions_detected.csv', index=False)\n",
    "\n",
    "print(\"Emotion detection completed and saved to issue_emotions_detected.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd6c3c8-7bc5-4aaf-a92c-c49d856edcee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tic",
   "language": "python",
   "name": "tic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
